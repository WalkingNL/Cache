## 高速缓冲池
将近5个月的时间，除了日常的质保，其余时间基本上都压在这个上面了。从零起步，然后是前期的需求调研，到初步方案的确定，再到最终方案落地，单这些就花了有两个月。接下来是代码实现，考虑到对Delphi的使用还不是特别顺手，所以就先用C++实现了一遍，之后再转为Delphi， 确实有点折腾。下面，具体来看一下。

#### 背景介绍
“我们的后台或许不慢了，只是后台的处理动作，被我们在前台感受到了”，我跟领导多次解释这一点。早些时候，投入了大量的精力提升后台的性能，也不负众望，从实际压测的效果来看，足以应对我们所有的需求。但和前台的实际交互效果，令人沮丧。其实，原因已不在后台，也就是说，改后台解决不了前后台交互效率低的问题。如下图所示

![FB.jpg](https://github.com/WalkingNL/Pics/blob/master/cache3.jpg)

可以看到，在结构上，前后台是进行直接交互的。只要前台触发一个动作，例如查询3000个数据，后台就会根据这个动作，先进行计算，然后筛选，再排序，最后把结果返回到前台。整个这一套过程可以用下图体现出来。

![](https://github.com/WalkingNL/Pics/blob/master/%E6%8C%87%E4%BB%A4%E6%97%B6%E9%97%B4.jpg)

需要解释一点，为了直观起见，数据的通信过程我单独的用下面的图来呈现。可以看到，前后台的数据交互在一个通道中进行，具体的通信时间由通道本身决定，我们无法对通道进行任何的优化。

![](https://github.com/WalkingNL/Pics/blob/master/%E9%80%9A%E9%81%93.jpg)

总结一下上述过程所用的时间，就是**后台处理数据的时间**，记为t1，加上数据通信的**往返时间**，记为t2，以及其它时间，记为t3，那么总时间T = t1 + t2 + t3。在这里假设t3可以忽略，那么T就由t1和t2来决定，根据以上的描述又知，t1经过了前期的优化，已经达到了期望的时效，那么瓶颈就在t2了，而我们又无法去优化它。

到这里，问题就交代清楚了。怎么解决这个问题，下一小节进行介绍。

#### 缓冲池原理
**本质上，缓冲池的加入，并不会改变通道本身的性能，它只是让前后台达到了在时效上的平稳过渡**。
###### 降耦
从上图可知，前后台是强依赖关系，而且通道对我们是一个黑匣子，所以无法对其进行直接优化。但又必须优化，那么很明显的一个策略就是**降偶**。嗯？什么是降耦呢？如下图所示。能够看到，在前台加入了一个缓冲池，让缓冲池作为前后台之间数据交换的一个中间件，这个中间件成为以后前后台交互的**主要渠道**。这里为什么说是主要渠道呢，从图中能够看出，前后台之间还存在一条微弱的联系，因为如果数据在缓冲池中没找到，就必须到后台去请求数据，所以这条微弱的联系，依然至关重要。这就是降耦，而不是解耦，因为后者意味着前后台不再有任何直接的联系。但如果那样，数据的完整性恐怕就存在问题了。[注：对于降偶和解耦这两个概念，仅适用于本文]。

![](https://github.com/WalkingNL/Pics/blob/master/cache1.jpg)

###### 数据更新
从上图可知，我们在前台，从结构上，做了一次分离。整体来说，将数据的加载与界面的展示分成两个部分。我们期望的效果是，界面将展示需要的数据，尽可能的从缓冲池中直接取得。而缓冲池中的数据加载及更新，或是从后台主动拉取，或是由后台直接推送。那么如何保证缓冲池中的数据一定是最新的？又如何协调前后不同的操作指令。为此，首先根据交互对象，将所有涉及的动作指令进行分类，见以下。*这里解释一下，省略了与业务相关的一些动作*。
  * 界面 - 缓冲池
    * 自动获取。又称定时刷新，规定界面每秒会执行一次刷新操作，意味着要从缓冲池中请求一次数据，并展示。
    * 手动获取。客户主动发起的请求操作，本文假设,除了时间因素之外(因为客户不会每秒都点击)，该操作触发的动作与**自动获取**完全相同。
  * 后台 - 缓冲池
    * 主动推送(push)。简称主推，规定后台每秒钟主动往前台推送一次数据。在加入了缓冲池之后，需要在这1秒内完成对缓冲池中数据的更新
    * 自动拉取(pull)。在极少的情况下，缓冲池中一直未能接收到新的数据，导致数据长时间得不到更新。此时，缓冲池会自动的向后台发出请求数据更新的操作。
  * 缓冲池(可选)
    * 自我更新。缓冲池除了它必要的桥梁作用之外，我们希望它能在一定程度上进行自我优化，并能收集一些有用的数据，提供后续分析。也正好，我们的业务提供了这方面必要的条件。对于缓冲池的自我优化，为了尽可能提高命中率，缓冲池在一些空闲的时刻，对数据节点作出一些标记，比如按照数据更改的频次，将一些惰性节点释放，减少不必要的空间损耗，等等！

#### 缓冲池实现
从这里开始，谈一下这个缓冲池的具体实现。
##### Hash + 跳跃表
###### 跳跃表
下图展示了一个跳跃表。其中数据域用**R*i***(0< i <= 30000)表示，**R**代表记录，**R*i***就表示第***i***个记录。对于这个跳跃表指针域的个数依据`2^x >= 30,000`，求取满足这个条件的最小*x*，然后*x*就作为指针域个数的最大值，因此每个节点的指针域的个数随机的分布在[1, x]内。关于这个随机算法的介绍，可以参看我之前写的这篇[文章](https://github.com/WalkingNL/Redis/blob/master/Redis内部数据结构之跳跃表(SkipList).md)。

![](https://github.com/WalkingNL/Pics/blob/master/SkipList9.jpg)

有了这个结构中之后，一个问题就随之而产生了，为什么要使用跳跃表？最为关键的原因是**区间查找**，这一点诸如二叉平衡树就很难做到。当然啦，这种结构的其它基本操作也是非常高效的，如插入、删除等。就不细说了，跳跃表的各种优势，上面链接中的文章，有详细的介绍。

###### Hash作为加速器
有了跳跃表之后，是不是一切就万事大吉了呢？想象一种情况，假如当前时刻为T，跳跃表的状态记为S。在它的下一个时刻T1时，从后台推送过来大量的的数据。看下图，记录为**R*i***的节点就在要更新的节点中。在S状态时，**R*i***的节点位于跳表的第***i***个节点，而现在这个位置要变化了。直接假设这个节点现在变成了跳表的第三个节点了，因此要对跳表的状态进行调整。有两种方式可以做到这一点，第一种，先将**R*i***取下，再插入到第三个位置上。第二种，重新生成一个新的节点，更新数据域，然后插入到第三个位置，再删除掉原来的**R*i***。这两种做法都是可行的，但是第一种做法存在的问题在于，将取下节点和插入节点这两个操作耦合在了一起，效率上有一定的影响。第二种做法的好处是，分离了插入和删除这两个操作。相比于第一种，在实现上，要复杂一些。但效率会高很多。

![](https://github.com/WalkingNL/Pics/blob/master/SkipList10.jpg)

不管咋样，一旦节点有更新，就可能需要调整节点的位置。一个节点代表一个用户的记录，一个记录有唯一的用户ID。这就是说，当某一个记录要更新时，必须先在跳表中查找，这个记录是否已经在，如果不在，找到插入的位置，插入节点。如果在，先要取下这个节点，并更新数据域，然后在插入到新的位置。这个过程，体现在下面的流程图中

![](https://github.com/WalkingNL/Pics/blob/master/cache2.jpg)

##### 

#### 问题分析
##### 冷启动


#### 后记
